html_text()
## first value is blank so remove it
num_goals_info_clean <- num_goals_info[-1]
}
num_assists_info <- function(session) {
num_assists_info <- scrape(session) %>%
html_nodes(".assists") %>%
html_text()
## first value is blank so remove it
num_assists_info_clean <- num_assists_info[-1]
}
premier_stats_info <- function(link, team_name) {
team_name <- rlang::enquo(team_name)
## `bow()` for every URL link
session <- bow(link)
## scrape different stats
player_name <- player_name_info(session = session)
num_goals <- num_goals_info(session = session)
num_assists <- num_assists_info(session = session)
## combine stats into a data frame
resultados <- list(player_name, num_goals, num_assists)
col_names <- c("name", "goals", "assists")
premier_stats <- resultados %>%
reduce(cbind) %>%
as_tibble() %>%
set_names(col_names) %>%
mutate(team = !!team_name)
return(premier_stats)
}
safe_premier_stats_info <- safely(premier_stats_info)
goal_contribution_df_ALL <- map2(.x = team_links_df$link, .y = team_links_df$team_name,
~ safe_premier_stats_info(link = .x, team_name = .y))
## check out the first 4 results:
glimpse(head(goal_contribution_df_ALL, 4))
team_name <- "blarghster town fc"
cat(team_name, " done!")
## check to see if any failed:
goal_contribution_df_ALL %>%
map("error") %>%
purrr::discard(~is.null(.))
goal_contribution_df <- goal_contribution_df_ALL %>%
map("result") %>%
bind_rows()
glimpse(goal_contribution_df)
knitr::opts_chunk$set(echo = TRUE)
jleague_table_2020_cleaned <- readr::read_csv("https://raw.githubusercontent.com/Ryo-N7/soccer_ggplots/master/data/J-League_2020_review/jleague_table_2020_cleaned.csv")
jleague_table_2020_cleaned %>%
kable(format = "html",
caption = "J.League 2020 Table") %>%
kable_styling(full_width = FALSE,
bootstrap_options = c("condensed", "responsive")) %>%
add_header_above(c(" ", "Result" = 4, "Goals" = 3,
"Expected Goals" = 3)) %>%
column_spec(1:2, bold = TRUE) %>%
row_spec(1, bold = TRUE, color = "white", background = "green") %>%
row_spec(2:3, bold = TRUE, color = "grey", background = "lightgreen") %>%
row_spec(4:15, bold = TRUE, color = "grey", background = "white") %>%
row_spec(16:18, color = "white", background = "red") %>%
add_footnote(label = "Data: FBref.com & Football-Lab.jp | Note: No relegation in 2020 season",
notation = "none")
?percent()
jleague_age_utility_df <- readr::read_csv("https://raw.githubusercontent.com/Ryo-N7/soccer_ggplots/master/data/J-League_2020_review/jleague_age_utility_df_2020.csv")
jleague_age_utility_df %>%
filter(age <= 23, min_perc >= 0.6) %>%
arrange(desc(minutes)) %>%
select(contains("name"), age, -fname, minutes, min_perc) %>%
mutate(min_perc = min_perc * 100) %>%
unite("Name", first_name, last_name, sep = " ") %>%
rename(Team = team_name, Age = age, Minutes = minutes,
`% of Total Minutes Played` = min_perc) %>%
kable() %>%
kable_styling(full_width = FALSE,
bootstrap_options = c("condensed", "responsive"))
library(dplyr)
library(tidyr)
library(readr)
library(knitr)
library(kableExtra)
jleague_age_utility_df <- readr::read_csv("https://raw.githubusercontent.com/Ryo-N7/soccer_ggplots/master/data/J-League_2020_review/jleague_age_utility_df_2020.csv")
jleague_age_utility_df %>%
filter(age <= 23, min_perc >= 0.6) %>%
arrange(desc(minutes)) %>%
select(contains("name"), age, -fname, minutes, min_perc) %>%
mutate(min_perc = min_perc * 100) %>%
unite("Name", first_name, last_name, sep = " ") %>%
rename(Team = team_name, Age = age, Minutes = minutes,
`% of Total Minutes Played` = min_perc) %>%
kable() %>%
kable_styling(full_width = FALSE,
bootstrap_options = c("condensed", "responsive"))
jleague_age_utility_df %>%
group_by(team_name) %>%
summarize(avgage = mean(age)) %>%
arrange(desc(avgage))
usethis::use_readme_rmd()
url <- "https://ryo-n7.github.io/"
session <- polite::bow(url)
library(dplyr)
library(tidyr)
library(rvest)
library(ggplot2)
library(polite)
session %>%
polite::scrape() %>%
html_nodes(".post-title") %>%
html_text()
blog_titles <- scrape(session) %>%
html_nodes(".post-title") %>%
html_text()
blog_dates <- scrape(session) %>%
html_nodes(".post-meta") %>%
html_text()
blog_dates <- scrape(session) %>%
html_nodes(".blog-tags") %>%
html_text()
blog_dates
blog_titles <- scrape(session) %>%
html_nodes(".post-title") %>%
html_text()
blog_dates <- scrape(session) %>%
html_nodes(".post-meta") %>%
html_text()
blog_tags <- scrape(session) %>%
html_nodes(".b
blog_dates
url <- "https://ryo-n7.github.io/"
session <- polite::bow(url)
blog_titles <- scrape(session) %>%
html_nodes(".post-title") %>%
html_text()
blog_dates <- scrape(session) %>%
html_nodes(".post-meta") %>%
html_text()
blog_tags <- scrape(session) %>%
html_nodes(".blog-tags") %>%
html_text()
blog_titles
blog_dates
blog_tags
blog_titles
blog_dates
library(stringr)
blog_dates %>%
str_trim()
blog_dates %>%
str_trim() %>%
str_remove_all("Posted on ")
library(lubridate)
blog_dates %>%
str_trim() %>%
str_remove_all("Posted on ") %>%
ymd()
blog_dates_clean <- blog_dates %>%
str_trim() %>%
str_remove_all("Posted on ")
blog_tags
blog_tags %>%
str_trim()
ags %>%
str_trim() %>%
str_remove_all("Tags:\n")
%>%
blog_tags %>%
str_trim() %>%
str_remove_all("Tags:\n")
blog_tags %>%
str_trim() %>%
str_remove_all("Tags:\n") %>%
str_remove_all("\n") %>%
str_trim()
blog_tags %>%
str_trim() %>%
str_remove_all("Tags:\n") %>%
str_remove_all("\n") %>%
str_remove_all("r-bloggers") %>%
str_trim()
blog_tags %>%
str_trim() %>%
str_remove_all("Tags:\n") %>%
str_replace_all("[:space:]", "")
blog_tags %>%
str_trim() %>%
str_remove_all("Tags:\n") %>%
str_replace_all("[:space:]", "") %>%
str_remove_all("r-bloggers")
blog_tags %>%
str_trim() %>%
str_remove_all("Tags:\n") %>%
str_replace_all("[:space:]", "") %>%
str_remove_all("r-bloggers") %>%
str_trim()
log_tags %>%
str_trim() %>%
str_remove_all("Tags:\n") %>%
str_replace_all("[:space:]", "") %>%
str_remove_all("r-bloggers")
blog_tags %>%
str_trim() %>%
str_remove_all("Tags:\n") %>%
str_replace_all("[:space:]", "") %>%
str_remove_all("r-bloggers")
blog_tags %>%
str_trim() %>%
str_remove_all("Tags:\n") %>%
str_replace_all("[:space:]", "") %>%
str_remove_all("r-bloggers") %>%
gsub(".{1}$", "")
blog_tags %>%
str_trim() %>%
str_remove_all("Tags:\n") %>%
str_replace_all("[:space:]", "") %>%
str_remove_all("r-bloggers") %>%
gsub(".{2}$", "")
blog_tags %>%
str_trim() %>%
str_remove_all("Tags:\n") %>%
str_replace_all("[:space:]", "") %>%
str_remove_all("r-bloggers") %>%
as_tibble()
blog_tags %>%
str_trim() %>%
str_remove_all("Tags:\n") %>%
str_replace_all("[:space:]", "") %>%
str_remove_all("r-bloggers") %>%
as_tibble() %>%
gsub(".{2}$", "", value)
blog_tags %>%
str_trim() %>%
str_remove_all("Tags:\n") %>%
str_replace_all("[:space:]", "") %>%
str_remove_all("r-bloggers") %>%
as_tibble() %>%
gsub(".{2}$", "")
blog_tags %>%
str_trim() %>%
str_remove_all("Tags:\n") %>%
str_replace_all("[:space:]", "") %>%
str_remove_all("r-bloggers") %>%
as_tibble() %>%
gsub(".{2}$", "")
blog_tags %>%
str_trim() %>%
str_remove_all("Tags:\n") %>%
str_replace_all("[:space:]", "") %>%
str_remove_all("r-bloggers") %>%
as_tibble()
blog_tags %>%
str_trim() %>%
str_remove_all("Tags:\n") %>%
str_replace_all("[:space:]", "") %>%
str_remove_all("r-bloggers") %>%
as_tibble() %>%
mutate(value2 = gsub(".{2}$", ""))
blog_tags %>%
str_trim() %>%
str_remove_all("Tags:\n") %>%
str_replace_all("[:space:]", "") %>%
str_remove_all("r-bloggers") %>%
as_tibble() %>%
mutate(value2 = gsub(".{2}$", "", value))
blog_tags %>%
str_trim() %>%
str_remove_all("Tags:\n") %>%
str_replace_all("[:space:]", "") %>%
str_remove_all("r-bloggers") %>%
as_tibble() %>%
mutate(value2 = gsub(".{1}$", "", value))
blog_tags %>%
str_trim() %>%
str_remove_all("Tags:\n") %>%
str_replace_all("[:space:]", "") %>%
str_remove_all(", r-bloggers")
blog_tags %>%
str_trim() %>%
str_remove_all("Tags:\n") %>%
str_replace_all("[:space:]", "") %>%
str_remove_all(",r-bloggers")
blog_tags <- scrape(session) %>%
html_nodes(".blog-tags") %>%
html_text()
blog_tags_clean <- blog_tags %>%
str_trim() %>%
str_remove_all("Tags:\n") %>%
str_replace_all("[:space:]", "") %>%
str_remove_all(",r-bloggers")
blog_tags_clean
posts_df <- tibble(blog_dates_clean, blog_titles, blog_tags_clean) %>%
transmute(
n = nrow(),
publish_date = ymd(blog_dates_clean),
title = blog_titles,
link = paste0(, link)
)
posts_df <- tibble(blog_dates_clean, blog_titles, blog_tags_clean) %>%
transmute(
n = nrow():1,
publish_date = ymd(blog_dates_clean),
title = blog_titles,
link = paste0(, link)
)
posts_df <- tibble(blog_dates_clean, blog_titles, blog_tags_clean) %>%
transmute(
n = nrow(.):1,
publish_date = ymd(blog_dates_clean),
title = blog_titles,
link = paste0(, link)
)
scrape(session) %>%
html_nodes(".post-title")
scrape(session) %>%
html_nodes(".post-title") %>% html_attr("href")
scrape(session) %>%
html_nodes(".post-title")
scrape(session) %>%
html_nodes(".post-title") -> asdf
View(asdf)
asdf[[1]]
asdf[[2]]
asdf[1]
asdf[1] %>% View()
blog_links <- scrape(session) %>%
html_nodes(".post-read-more")
blog_links
blog_links <- scrape(session) %>%
html_nodes(".post-read-more") %>%
html_attr("href")
blog_links
base_url <- "https://ryo-n7.github.io/"
posts_df <- tibble(blog_dates_clean, blog_titles, blog_tags_clean) %>%
transmute(
n = nrow(.):1,
publish_date = ymd(blog_dates_clean),
title = blog_titles,
link = paste0(base_url, blog_links)
)
posts_df
blog_dates_clean
mdy(blog_dates_clean)
posts_df <- tibble(blog_dates_clean, blog_titles, blog_tags_clean) %>%
transmute(
n = nrow(.):1,
publish_date = mdy(blog_dates_clean),
title = blog_titles,
link = paste0(base_url, blog_links)
)
posts_df
library(purrr)
scrape_ryon7 <- function(base_url = "https://ryo-n7.github.io/") {
session <- polite::bow(base_url)
blog_titles <- scrape(session) %>%
html_nodes(".post-title") %>%
html_text()
blog_links <- scrape(session) %>%
html_nodes(".post-read-more") %>%
html_attr("href")
blog_dates <- scrape(session) %>%
html_nodes(".post-meta") %>%
html_text()
blog_dates_clean <- blog_dates %>%
str_trim() %>%
str_remove_all("Posted on ")
blog_tags <- scrape(session) %>%
html_nodes(".blog-tags") %>%
html_text()
blog_tags_clean <- blog_tags %>%
str_trim() %>%
str_remove_all("Tags:\n") %>%
str_replace_all("[:space:]", "") %>%
str_remove_all(",r-bloggers")
posts_data <- tibble(blog_dates_clean, blog_titles, blog_tags_clean) %>%
transmute(
n = nrow(.):1,
publish_date = mdy(blog_dates_clean),
title = blog_titles,
link = paste0(base_url, blog_links)
)
return(posts_data)
}
posts_df <- scrape_ryon7(base_url = "https://ryo-n7.github.io/")
posts_df
View(posts_df)
scrape_ryon7 <- function(base_url = "https://ryo-n7.github.io/") {
session <- polite::bow(base_url)
blog_titles <- scrape(session) %>%
html_nodes(".post-title") %>%
html_text()
blog_links <- scrape(session) %>%
html_nodes(".post-read-more") %>%
html_attr("href")
blog_dates <- scrape(session) %>%
html_nodes(".post-meta") %>%
html_text()
blog_dates_clean <- blog_dates %>%
str_trim() %>%
str_remove_all("Posted on ")
blog_tags <- scrape(session) %>%
html_nodes(".blog-tags") %>%
html_text()
blog_tags_clean <- blog_tags %>%
str_trim() %>%
str_remove_all("Tags:\n") %>%
str_replace_all("[:space:]", "") %>%
str_remove_all(",r-bloggers")
posts_data <- tibble(blog_dates_clean, blog_titles, blog_tags_clean) %>%
transmute(
n = nrow(.):1,
publish_date = mdy(blog_dates_clean),
title = blog_titles,
tags = blog_tags,
link = paste0(base_url, blog_links)
)
return(posts_data)
}
posts_df <- scrape_ryon7(base_url = "https://ryo-n7.github.io/")
posts_df
View(posts_df)
scrape_ryon7 <- function(base_url = "https://ryo-n7.github.io/") {
session <- polite::bow(base_url)
blog_titles <- scrape(session) %>%
html_nodes(".post-title") %>%
html_text()
blog_links <- scrape(session) %>%
html_nodes(".post-read-more") %>%
html_attr("href")
blog_dates <- scrape(session) %>%
html_nodes(".post-meta") %>%
html_text()
blog_dates_clean <- blog_dates %>%
str_trim() %>%
str_remove_all("Posted on ")
blog_tags <- scrape(session) %>%
html_nodes(".blog-tags") %>%
html_text()
blog_tags_clean <- blog_tags %>%
str_trim() %>%
str_remove_all("Tags:\n") %>%
str_replace_all("[:space:]", "") %>%
str_remove_all(",r-bloggers")
posts_data <- tibble(blog_dates_clean, blog_titles, blog_tags_clean) %>%
transmute(
n = nrow(.):1,
publish_date = mdy(blog_dates_clean),
title = blog_titles,
tags = blog_tags_clean,
link = paste0(base_url, blog_links)
)
return(posts_data)
}
posts_df <- scrape_ryon7(base_url = "https://ryo-n7.github.io/")
View(posts_df)
library(dplyr)
library(tidyr)
library(rvest)
library(ggplot2)
library(polite)
library(stringr)
library(lubridate)
library(purrr)
scrape_ryon7 <- function(base_url = "https://ryo-n7.github.io/") {
session <- polite::bow(base_url)
blog_titles <- scrape(session) %>%
html_nodes(".post-title") %>%
html_text()
blog_links <- scrape(session) %>%
html_nodes(".post-read-more") %>%
html_attr("href")
blog_dates <- scrape(session) %>%
html_nodes(".post-meta") %>%
html_text()
blog_dates_clean <- blog_dates %>%
str_trim() %>%
str_remove_all("Posted on ")
blog_tags <- scrape(session) %>%
html_nodes(".blog-tags") %>%
html_text()
blog_tags_clean <- blog_tags %>%
str_trim() %>%
str_remove_all("Tags:\n") %>%
str_replace_all("[:space:]", "") %>%
str_remove_all(",r-bloggers")
posts_data <- tibble(blog_dates_clean, blog_titles, blog_tags_clean) %>%
transmute(
n = nrow(.):1,
publish_date = mdy(blog_dates_clean),
title = blog_titles,
tags = blog_tags_clean,
link = paste0(base_url, blog_links)
)
return(posts_data)
}
posts_df <- scrape_ryon7(base_url = "https://ryo-n7.github.io/")
usethis::use_github_action("render-rmarkdown.yaml")
?polite
??polite
library(emo)
publish_plot <- posts_data %>%
ggplot(aes(x = publish_date, y = 1)) +
geom_point(shape = "|", size = 10, stroke = 1, color = "#1D8016") +
theme_void()
publish_plot <- posts_df %>%
ggplot(aes(x = publish_date, y = 1)) +
geom_point(shape = "|", size = 10, stroke = 1, color = "#1D8016") +
theme_void()
publish_plot
today()
publish_plot <- posts_df %>%
ggplot(aes(x = publish_date, y = 1)) +
geom_point(shape = "|", size = 10, stroke = 1, color = "#1D8016") +
theme_void()
emo::ji("date")
emo::ji()
emo::ji("star")
