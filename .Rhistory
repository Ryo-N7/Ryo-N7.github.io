ggplot(sakura, aes(x = year, y = Day_Of_Year)) +  # or just use original 'year' variable...
geom_point() +
geom_smooth(span = 0.2, size = 3, method = "gam") +
scale_y_continuous(labels = function(x) format(as.Date(as.character(x), "%j"), "%b-%d"),
limits = c(84, 125))
ggplot(sakura, aes(x = year, y = Day_Of_Year)) +  # or just use original 'year' variable...
geom_point() +
geom_smooth(span = 0.2, size = 3, method = "gam", formula = y~s(x, bs = "cs")) +
scale_y_continuous(labels = function(x) format(as.Date(as.character(x), "%j"), "%b-%d"),
limits = c(84, 125))
ggplot(sakura, aes(x = year, y = Day_Of_Year)) +  # or just use original 'year' variable...
geom_point() +
geom_smooth(span = 0.2, size = 3) +
scale_y_continuous(labels = function(x) format(as.Date(as.character(x), "%j"), "%b-%d"),
limits = c(84, 125))
ggplot(sakura, aes(x = year, y = Day_Of_Year)) +  # or just use original 'year' variable...
geom_point() +
geom_smooth(span = 0.2, size = 3, method = "gam", formula = y~s(x, bs = "cs")) +
scale_y_continuous(labels = function(x) format(as.Date(as.character(x), "%j"), "%b-%d"),
limits = c(84, 125))
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
# Global Peace Index
library(tidyverse)          # includes dplyr, tidyr, ggplot2
library(scales)             # more options for scales on plots
library(ggrepel)            # dealing with overlapping text/labels
library(rvest)              # for web scraping: read_html(), html_table() functions
library(stringr)            # dealing with strings
library(forcats)            # change factor levels manually
# Web scrape: -------------------------------------------------------------
url <- "https://en.wikipedia.org/wiki/Global_Peace_Index"
GPI <- url %>%
read_html() %>%
html_nodes('table.wikitable:nth-child(29)') %>%
.[[1]] %>%
html_table()
# Inspect scraped data ----------------------------------------------------
glimpse(GPI)
# Tidy dataset ------------------------------------------------------------
GPI_rank <- GPI %>% select(Country, ends_with("rank"))
colnames(GPI_rank) <- colnames(GPI_rank) %>% tolower()   # turn "Country" into lower case...
glimpse(GPI_rank)
GPI_rank <- GPI_rank %>% gather(`2017 rank`:`2008 rank`, key = "year", value = "rank")
glimpse(GPI_rank)
GPI_rank$year <- GPI_rank$year %>% str_replace_all("rank", "") %>% trimws()
glimpse(GPI_rank)
GPI_rank <- GPI_rank %>% mutate(year = as.factor(year))
levels(GPI_rank$year)     # now as factor + no "rank" afterwards.
GPI_rank %>% head(15)
GPI_rank <- GPI_rank %>% mutate(rank = str_replace(rank, "\\=", ""))   #   take out '=' in rank values
GPI_rank$year <- GPI_rank$year %>% str_replace_all("rank", "") %>% trimws()
glimpse(GPI_rank)
GPI_rank <- GPI_rank %>% mutate(rank = str_replace(rank, "\\=", ""))   #   take out '=' in rank values
GPI_rank$rank <- as.numeric(GPI_rank$rank)
GPI_rank <- GPI_rank %>% arrange(year, rank)
glimpse(GPI_rank)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
# Packages:
library(tidyverse)  # for dplyr, tidyr, ggplot2
library(tidytext)   # for separating text into words with unnest_tokens() function
library(stringr)    # for string detection, extraction, manipulation, etc.
library(gplots)     # for a certain type of plots not in ggplot2
library(ggrepel)    # for making sure labels don't overlap
library(scales)     # for fixing and tweaking the scales on graphs
library(gridExtra)  # for arranging multiple plots into a single page
library(lubridate)
df <- read.csv('~/R_materials/ThriceLyrics/thrice.df.csv', header=TRUE, stringsAsFactors = FALSE)
df <- df %>%
mutate(album = factor(album, levels = unique(album)),
length = ms(length),
lengthS = seconds(length))
df %>%
select(lyrics) %>%
substr(4, 116)
library(stringr)
# use the stringr for str_split() function to split "lyrics" on the <br> tags!
wordToken <-  df %>%
unnest_tokens(output = line, input = lyrics, token = str_split, pattern = ' <br>') %>%
unnest_tokens(output = word, input = line)
glimpse(wordToken)
countWord <- wordToken %>% count(word, sort=TRUE)
countWord  %>% head(10)
data("stop_words")
set.seed(1)
sample_stop <- stop_words %>% sample_n(10)
sample_stop
wordToken2 <- wordToken %>%
anti_join(stop_words) %>% # Take out rows of `word` in wordToken that appear in stop_words
arrange(ID)               # Can also arrange by track_num, basically the same thing
countWord2 <- wordToken2 %>% count(word, sort = TRUE)
countWord2 %>% head(10)
# graph of most common words (including stop words)
one <- countWord %>% head(10) %>%
ggplot(aes(reorder(word, n), n)) +
geom_bar(stat = "identity", fill = "darkgreen", alpha = 0.75) +
ggtitle("Comparison of 'Most Common Words'") +
labs(x = "With 'stop words'", y = "Frequency") +
scale_y_continuous(breaks = pretty_breaks(5)) +
coord_flip() +
theme_bw() +
theme(panel.grid.major.x = element_line(size = 1.25),
axis.text.x = element_text(size = 12, face = "bold"),
plot.title = element_text(hjust = 0.5))
# graph of most common words (no stop words)
two <- countWord2 %>% head(10) %>%
ggplot(aes(reorder(word, n), n)) +
geom_bar(stat = "identity", fill = "darkgreen", alpha = 0.75) +
labs(x = "No 'stop words'", y = "Frequency") +
scale_y_continuous(breaks = pretty_breaks()) +
coord_flip() +
theme_bw() +
theme(panel.grid.major.x = element_line(size = 1.25),
axis.text.x = element_text(size = 12, face = "bold"))
grid.arrange(one, two)
library(wordcloud)
layout(matrix(c(1,2),1,2, byrow = TRUE))
wordcloud(words = countWord$word, freq = countWord$n, random.order = FALSE, max.words = 300,
colors = brewer.pal(8, "Dark2"), use.r.layout = TRUE)
wordcloud(countWord2$word, countWord2$n, random.order = FALSE, max.words = 300,
colors = brewer.pal(8, "Dark2"), use.r.layout = TRUE)
wordToken %>% select(title) %>% n_distinct()
wordToken2 %>% select(title) %>% n_distinct()
df %>% summarise(num_songs = n()) # 103 songs in total, as each row = 1 song in original data set
wordToken %>% select(word) %>% n_distinct()
wordToken2 %>% select(word) %>% n_distinct()
# WordsPerSong
WordsPerSong <- wordToken %>%
group_by(title) %>%
summarize(wordcounts = n()) %>%    # each row = 1 word
arrange(desc(wordcounts))
WordsPerSong %>%
ggplot(aes(x = wordcounts)) +
geom_histogram(bins = 50, color = "white", fill = "darkgreen") +
geom_vline(xintercept = median(WordsPerSong$wordcounts),
color = "red", linetype = "dashed", size = 1.25) +
scale_y_continuous(breaks = pretty_breaks(), expand = c(0, 0), limits = c(0, 12)) +
scale_x_continuous(breaks = pretty_breaks(10), expand = c(0, 0), limits = c(0, 410)) +
xlab('Total # of Words') +
ylab('# of Songs') +
labs(title = 'Distribution of Songs by Number of Words \n (Dashed red line: median)') +
theme_bw() +
theme(panel.grid.minor = element_blank(),
plot.title = element_text(hjust = 0.5))
wordToken2 %>%
group_by(album) %>%
summarize(num_songs = n_distinct(title)) %>%
arrange(desc(num_songs))
wordToken %>%
select(title, album, word) %>%
group_by(title, album) %>%
summarize(num_word = n()) %>%
arrange(desc(num_word)) %>%
head(10)
wordToken %>%
select(album, word) %>%
group_by(album) %>%
summarize(num_word = n()) %>%
arrange(desc(num_word)) %>%
ggplot(aes(reorder(album, num_word), num_word, fill = num_word)) +
geom_bar(stat = "identity") +
scale_y_continuous(expand = c(0.01, 0)) +
scale_fill_gradient(low = "#a1d99b", high = "#006d2c", guide = FALSE) +
coord_flip() +
theme_bw() +
theme(axis.text.y = element_text(size = 8), axis.title.y = element_blank()) +
ylab("Number of Words")
wordToken %>%
filter(album == "Vheissu") %>%
summarize(num_word = n())
wordToken %>%
filter(title == "The Weight") %>%
summarize(num_word = n())
wordToken2 %>%
filter(title == "The Weight") %>%
group_by(title) %>%
count(word) %>%
arrange(desc(n)) %>%
head(5)
wordToken2 %>%
str_count("light") %>%
sum()
wordToken2 %>%
select(title, album, word) %>%
mutate(light = str_count(word, "light")) %>%
group_by(title, album) %>%
summarize(total_light = sum(light)) %>%
arrange(desc(total_light)) %>%
head(5)
wordToken %>%
select(title, album, word) %>%
summarize(light = str_count(word, "light") %>% sum(),
num_word = n(),
prop_light = (light / num_word))
wordToken %>%
group_by(title) %>%
count(word) %>%
arrange(desc(n)) %>%
head(10)
wordToken2 %>%
group_by(title) %>%
count(word, sort = TRUE) %>%
head(10)
wordToken2 %>%
filter(title == "Black Honey") %>%
count(word, sort = TRUE) %>%
head(10)
wordToken2 %>%
group_by(album, word) %>%
summarize(count = n(), sort = TRUE) %>%
top_n(5)
wordToken2 %>%
group_by(album, word) %>%
summarize(count = n(), sort = TRUE)
wordToken2 %>%
group_by(album, word) %>%
summarize(count = n(), sort = TRUE) %>%
top_n(count, 5)
wordToken2 %>%
group_by(album, word) %>%
summarize(count = n(), sort = TRUE) %>%
top_n(5, wt = count)
word_count_nested$data[[1]]
# most frequent unigrams per album: ####
word_count_nested <- wordToken2 %>%
group_by(album, word) %>%
summarize(count = n(), sort = TRUE) %>%
top_n(5, wt = count) %>%
arrange(album, desc(count)) %>%
nest()
word_count_nested$data[[1]]
word_count_nested$data[[5]]
word_count_nested <- word_count_nested %>%
mutate(plot = map2(data, album,
~ggplot(data = .x, aes(fill = count)) +
geom_bar(aes(reorder(word, count), count),
stat = "identity", width = 0.65) +
scale_y_continuous(breaks = pretty_breaks(10), limits = c(0, 22), expand = c(0, 0)) +
scale_fill_gradient(low = "#a1d99b", high = "#006d2c", guide = FALSE) +
ggtitle(.y) +
labs(x = NULL, y = NULL) +
coord_flip() +
theme_bw() +
theme(axis.text.y = element_text(size = 7),
title = element_text(size = 10))
))
str(word_count_nested, list.len = 3, max.level = 2)
word_count_nested$data[[1]]
word_count_nested$data[[5]]
word_count_nested <- word_count_nested %>%
mutate(plot = map2(data, album,
~ggplot(data = .x, aes(fill = count)) +
geom_bar(aes(reorder(word, count), count),
stat = "identity", width = 0.65) +
scale_y_continuous(breaks = pretty_breaks(10), limits = c(0, 22), expand = c(0, 0)) +
scale_fill_gradient(low = "#a1d99b", high = "#006d2c", guide = FALSE) +
ggtitle(.y) +
labs(x = NULL, y = NULL) +
coord_flip() +
theme_bw() +
theme(axis.text.y = element_text(size = 7),
title = element_text(size = 10))
))
str(word_count_nested, list.len = 3, max.level = 2)
word_count_nested$plot[[2]]
word_count_nested$plot[[11]]
word_count_nested$plot[[2]]
word_count_nested$plot[[11]]
nested_plots <- word_count_nested$plot[1:4]
str(nested_plots, list.len = 2, max.level = 2)
library(cowplot)
plot_grid(plotlist = nested_plots, ncol = 2)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
GPI <- read.csv("~/R_materials/globa_peace_index/GPI_raw.csv", stringsAsFactors = FALSE)
??calcHumx
Sys.setenv("tar" = "internal")
remotes::install_github("JohnCoene/shticky")
library(shiny)
library(shticky)
longdiv <- function(...){
div(style = "min-height:100vh;", ...)
}
ui <- fluidPage(
use_shticky(),
h1(id = "stick", "SHTICKY"),
longdiv(),
longdiv(
verbatimTextOutput("sticky")
),
actionButton("unstick", "UNSHTICK")
)
server <- function(input, output, session) {
shtick <- Shtick$
new("#stick")$
shtick()
output$sticky <- renderPrint({
input$shtuck
})
observeEvent(input$unstick, {
shtick$unshtick()
})
}
shinyApp(ui, server)
library(magick)
img <- image_read("https://github.com/Ryo-N7/Ryo-N7.github.io/blob/master/assets/2019-04-24-tokyoR-77_files/tokyorlogo.png")
img <- image_read("assets/2019-04-24-tokyoR-77_files/tokyorlogo.png")
img
image_scale(img, "1000x600")
airquality %>%
mutate(Month = as.factor(Month)) %>%
ggplot(aes(x = Day, y = Temp, group = Month, color = Month)) +
geom_point(size = 2.5) +
labs(title = "Calzones are pointless.", subtitle = "They're just pizza that's harder to eat!",
caption = "No one likes them. Good day, sir.") +
scale_color_parksAndRec() +
theme_minimal() +
theme_parksAndRec(text.font = "Titillium Web",
title.font = "Titillium Web Black",
legend.font = "Titillium Web") -> parksandrec
pacman::p_load(ggplot2, dplyr, tvthemes, extrafont,
glue, gapminder, emo, patchwork, cowplot)
loadfonts()
airquality %>%
mutate(Month = as.factor(Month)) %>%
ggplot(aes(x = Day, y = Temp, group = Month, color = Month)) +
geom_point(size = 2.5) +
labs(title = "Calzones are pointless.", subtitle = "They're just pizza that's harder to eat!",
caption = "No one likes them. Good day, sir.") +
scale_color_parksAndRec() +
theme_minimal() +
theme_parksAndRec(text.font = "Titillium Web",
title.font = "Titillium Web Black",
legend.font = "Titillium Web") -> parksandrec
mpg %>%
ggplot(aes(displ)) +
geom_histogram(aes(fill = class), col = "black", size = 0.1) +
labs(title = "Parks & Recreation",
subtitle = "Gotta Spend Money To Make Money!",
caption = "And I spent... all of my money!") +
scale_fill_parksAndRec() +
theme_minimal() +
theme_parksAndRec_light(title.font = "Titillium Web Black",
text.font = "Titillium Web") -> parksandreclight
## plot together:
plot_grid(parksandrec, parksandreclight)
usethis::use_code_of_conduct()
?usethis::use_spell_check
?usethis::use_badge()
scales::show_col(tvthemes:::rickAndMorty_palette)
scales::show_col(tvthemes:::lannister_palette)
scales::show_col(tvthemes:::simpsons_palette)
knitr::opts_chunk$set(echo = TRUE)
install.packages("tvthemes") # v1.1.0
library(tvthemes)
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(tvthemes, ggplot2, dplyr)
scales::show_col(gravityFalls_pal())
scales::show_col(gravityFalls_palette)
scales::show_col(tvthemes:::gravityFalls_palette)
data <- gapminder::gapminder %>%
filter(country %in% c("Ireland", "Italy", "Turkey", "France", "Germany",
"Brazil", "Mexico", "Sweden", "Netherlands",
"Greece", "Spain", "Finland", "United Kingdom")) %>%
mutate(year = as.Date(paste(year, "-01-01", sep = "", format = '%Y-%b-%d')),
image = "")
ggplot(data = data, aes(x = year, y = gdpPercap, fill = country)) +
geom_area(alpha = 0.9) +
scale_x_date(expand = c(0, 0), breaks = data$year, date_labels = "%Y") +
scale_y_continuous(expand = c(0, 0), labels = scales::dollar) +
scale_fill_gravityFalls(reverse = FALSE) +
labs(title = stringr::str_wrap("Well, Duck-tective, it seems you've really... quacked the case!", width = 70),
subtitle = "Quack-quack Quack-quack-quack (Don't patronize me!)",
caption = "Schmebulock!!",
x = "Years That Stanford Was Gone", y = "# of Sham Total sold") +
theme_avatar(title.font = "Gravitation Falls",
text.font = "Gravitation Falls",
title.size = 24,
subtitle.size = 20,
text.size = 18,
legend.position = "none")
pacman::p_load(tvthemes, ggplot2, dplyr, extrafont)
loadfonts()
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(tvthemes, ggplot2, dplyr, extrafont)
loadfonts(quiet = TRUE)
data <- gapminder::gapminder %>%
filter(country %in% c("Ireland", "Italy", "Turkey", "France", "Germany",
"Brazil", "Mexico", "Sweden", "Netherlands",
"Greece", "Spain", "Finland", "United Kingdom")) %>%
mutate(year = as.Date(paste(year, "-01-01", sep = "", format = '%Y-%b-%d')),
image = "")
ggplot(data = data, aes(x = year, y = gdpPercap, fill = country)) +
geom_area(alpha = 0.9) +
scale_x_date(expand = c(0, 0), breaks = data$year, date_labels = "%Y") +
scale_y_continuous(expand = c(0, 0), labels = scales::dollar) +
scale_fill_gravityFalls(reverse = FALSE) +
labs(title = stringr::str_wrap("Well, Duck-tective, it seems you've really... quacked the case!", width = 70),
subtitle = "Quack-quack Quack-quack-quack (Don't patronize me!)",
caption = "Schmebulock!!",
x = "Years That Stanford Was Gone", y = "# of Sham Total sold") +
theme_avatar(title.font = "Gravitation Falls",
text.font = "Gravitation Falls",
title.size = 24,
subtitle.size = 20,
text.size = 18,
legend.position = "none")
data <- gapminder::gapminder %>%
filter(country %in% c("Ireland", "Italy", "Turkey", "France", "Germany",
"Brazil", "Mexico", "Sweden", "Netherlands",
"Greece", "Spain", "Finland", "United Kingdom")) %>%
mutate(year = as.Date(paste(year, "-01-01", sep = "", format = '%Y-%b-%d')),
image = "")
ggplot(data = data, aes(x = year, y = gdpPercap, fill = country)) +
geom_area(alpha = 0.9) +
scale_x_date(expand = c(0, 0), breaks = data$year, date_labels = "%Y") +
scale_y_continuous(expand = c(0, 0), labels = scales::dollar) +
scale_fill_gravityFalls(reverse = FALSE) +
labs(title = stringr::str_wrap("Well, Duck-tective, it seems you've really... quacked the case!", width = 70),
subtitle = "Quack-quack Quack-quack-quack (Don't patronize me!)",
caption = "Schmebulock!!",
x = "Years That Stanford Was Gone", y = "# of Sham Total sold") +
theme_avatar(title.font = "Gravitation Falls",
text.font = "Gravitation Falls",
title.size = 24,
subtitle.size = 20,
text.size = 18,
legend.position = "none")
rweekly.highlights::run_app()
rlang::!!
rlang::`!!``
rlang::`!!`
rlang::`!!`
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
goal_contribution_df_ALL <- readRDS("C:/Users/Ryo Nakagawara/Documents/R_materials/soccer_ggplots/data/goalcontrib_webscrape_tutorial.RDS")
goal_contribution_df <- goal_contribution_df_ALL %>%
map("result") %>%
bind_rows()
View(goal_contribution_df_ALL)
?enquote
?enquo
library(rvest)
library(polite)
library(dplyr)
library(tidyr)
library(purrr)
library(stringr)
library(glue)
library(rlang)
url <- "https://us.soccerway.com/national/england/premier-league/20182019/regular-season/r48730/"
session <- bow(url)
session
team_links <- scrape(session) %>%
html_nodes("#page_competition_1_block_competition_tables_8_block_competition_league_table_1_table .large-link a") %>%
html_attr("href")
team_links[[1]]
team_links_df <- team_links %>%
tibble::enframe(name = NULL) %>%
## separate out each component of the URL by / and give them a name
tidyr::separate(value, c(NA, NA, NA, "team_name", "team_num"), sep = "/") %>%
## glue together the "team_name" and "team_num" into a complete URL
mutate(link = glue("https://us.soccerway.com/teams/england/{team_name}/{team_num}/squad/"))
glimpse(team_links_df)
player_name_info <- function(session) {
player_name_info <- scrape(session) %>%
html_nodes("#page_team_1_block_team_squad_3-table .name.large-link") %>%
html_text()
}
num_goals_info <- function(session) {
num_goals_info <- scrape(session) %>%
html_nodes(".goals") %>%
html_text()
## first value is blank so remove it
num_goals_info_clean <- num_goals_info[-1]
}
num_assists_info <- function(session) {
num_assists_info <- scrape(session) %>%
html_nodes(".assists") %>%
html_text()
## first value is blank so remove it
num_assists_info_clean <- num_assists_info[-1]
}
premier_stats_info <- function(link, team_name) {
team_name <- rlang::enquo(team_name)
## `bow()` for every URL link
session <- bow(link)
## scrape different stats
player_name <- player_name_info(session = session)
num_goals <- num_goals_info(session = session)
num_assists <- num_assists_info(session = session)
## combine stats into a data frame
resultados <- list(player_name, num_goals, num_assists)
col_names <- c("name", "goals", "assists")
premier_stats <- resultados %>%
reduce(cbind) %>%
as_tibble() %>%
set_names(col_names) %>%
mutate(team = !!team_name)
return(premier_stats)
}
safe_premier_stats_info <- safely(premier_stats_info)
goal_contribution_df_ALL <- map2(.x = team_links_df$link, .y = team_links_df$team_name,
~ safe_premier_stats_info(link = .x, team_name = .y))
## check out the first 4 results:
glimpse(head(goal_contribution_df_ALL, 4))
team_name <- "blarghster town fc"
cat(team_name, " done!")
## check to see if any failed:
goal_contribution_df_ALL %>%
map("error") %>%
purrr::discard(~is.null(.))
goal_contribution_df <- goal_contribution_df_ALL %>%
map("result") %>%
bind_rows()
glimpse(goal_contribution_df)
